<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<style>body{background-color:white;}</style>


</head>
<body>
<div id="nymfupzpof" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
  <style>#nymfupzpof table {
font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
}
#nymfupzpof thead, #nymfupzpof tbody, #nymfupzpof tfoot, #nymfupzpof tr, #nymfupzpof td, #nymfupzpof th {
border-style: none;
}
#nymfupzpof p {
margin: 0;
padding: 0;
}
#nymfupzpof .gt_table {
display: table;
border-collapse: collapse;
line-height: normal;
margin-left: auto;
margin-right: auto;
color: #333333;
font-size: 11px;
font-weight: normal;
font-style: none;
background-color: #FFFFFF;
width: auto;
border-top-style: none;
border-top-width: 2px;
border-top-color: #A8A8A8;
border-right-style: none;
border-right-width: 2px;
border-right-color: #D3D3D3;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #A8A8A8;
border-left-style: none;
border-left-width: 2px;
border-left-color: #D3D3D3;
}
#nymfupzpof .gt_caption {
padding-top: 4px;
padding-bottom: 4px;
}
#nymfupzpof .gt_title {
color: #333333;
font-size: 125%;
font-weight: initial;
padding-top: 4px;
padding-bottom: 4px;
padding-left: 5px;
padding-right: 5px;
border-bottom-color: #FFFFFF;
border-bottom-width: 0;
}
#nymfupzpof .gt_subtitle {
color: #333333;
font-size: 85%;
font-weight: initial;
padding-top: 3px;
padding-bottom: 5px;
padding-left: 5px;
padding-right: 5px;
border-top-color: #FFFFFF;
border-top-width: 0;
}
#nymfupzpof .gt_heading {
background-color: #FFFFFF;
text-align: center;
border-bottom-color: #FFFFFF;
border-left-style: none;
border-left-width: 1px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 1px;
border-right-color: #D3D3D3;
}
#nymfupzpof .gt_bottom_border {
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
}
#nymfupzpof .gt_col_headings {
border-top-style: none;
border-top-width: 2px;
border-top-color: #D3D3D3;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
border-left-style: none;
border-left-width: 1px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 1px;
border-right-color: #D3D3D3;
}
#nymfupzpof .gt_col_heading {
color: #333333;
background-color: #CCCCCC;
font-size: 11px;
font-weight: bold;
text-transform: inherit;
border-left-style: none;
border-left-width: 1px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 1px;
border-right-color: #D3D3D3;
vertical-align: bottom;
padding-top: 5px;
padding-bottom: 6px;
padding-left: 5px;
padding-right: 5px;
overflow-x: hidden;
}
#nymfupzpof .gt_column_spanner_outer {
color: #333333;
background-color: #CCCCCC;
font-size: 11px;
font-weight: bold;
text-transform: inherit;
padding-top: 0;
padding-bottom: 0;
padding-left: 4px;
padding-right: 4px;
}
#nymfupzpof .gt_column_spanner_outer:first-child {
padding-left: 0;
}
#nymfupzpof .gt_column_spanner_outer:last-child {
padding-right: 0;
}
#nymfupzpof .gt_column_spanner {
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
vertical-align: bottom;
padding-top: 5px;
padding-bottom: 5px;
overflow-x: hidden;
display: inline-block;
width: 100%;
}
#nymfupzpof .gt_spanner_row {
border-bottom-style: hidden;
}
#nymfupzpof .gt_group_heading {
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
color: #333333;
background-color: #FFFFFF;
font-size: 100%;
font-weight: initial;
text-transform: inherit;
border-top-style: none;
border-top-width: 2px;
border-top-color: #D3D3D3;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
border-left-style: none;
border-left-width: 1px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 1px;
border-right-color: #D3D3D3;
vertical-align: middle;
text-align: left;
}
#nymfupzpof .gt_empty_group_heading {
padding: 0.5px;
color: #333333;
background-color: #FFFFFF;
font-size: 100%;
font-weight: initial;
border-top-style: none;
border-top-width: 2px;
border-top-color: #D3D3D3;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
vertical-align: middle;
}
#nymfupzpof .gt_from_md > :first-child {
margin-top: 0;
}
#nymfupzpof .gt_from_md > :last-child {
margin-bottom: 0;
}
#nymfupzpof .gt_row {
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
margin: 10px;
border-top-style: none;
border-top-width: 1px;
border-top-color: #D3D3D3;
border-left-style: none;
border-left-width: 1px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 1px;
border-right-color: #D3D3D3;
vertical-align: middle;
overflow-x: hidden;
}
#nymfupzpof .gt_stub {
color: #333333;
background-color: #FFFFFF;
font-size: 100%;
font-weight: initial;
text-transform: inherit;
border-right-style: none;
border-right-width: 2px;
border-right-color: #D3D3D3;
padding-left: 5px;
padding-right: 5px;
}
#nymfupzpof .gt_stub_row_group {
color: #333333;
background-color: #FFFFFF;
font-size: 100%;
font-weight: initial;
text-transform: inherit;
border-right-style: none;
border-right-width: 2px;
border-right-color: #D3D3D3;
padding-left: 5px;
padding-right: 5px;
vertical-align: top;
}
#nymfupzpof .gt_row_group_first td {
border-top-width: 2px;
}
#nymfupzpof .gt_row_group_first th {
border-top-width: 2px;
}
#nymfupzpof .gt_summary_row {
color: #333333;
background-color: #FFFFFF;
text-transform: inherit;
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
}
#nymfupzpof .gt_first_summary_row {
border-top-style: none;
border-top-color: #D3D3D3;
}
#nymfupzpof .gt_first_summary_row.thick {
border-top-width: 2px;
}
#nymfupzpof .gt_last_summary_row {
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
}
#nymfupzpof .gt_grand_summary_row {
color: #333333;
background-color: #FFFFFF;
text-transform: inherit;
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
}
#nymfupzpof .gt_first_grand_summary_row {
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
border-top-style: none;
border-top-width: 6px;
border-top-color: #D3D3D3;
}
#nymfupzpof .gt_last_grand_summary_row_top {
padding-top: 8px;
padding-bottom: 8px;
padding-left: 5px;
padding-right: 5px;
border-bottom-style: none;
border-bottom-width: 6px;
border-bottom-color: #D3D3D3;
}
#nymfupzpof .gt_striped {
background-color: #EEEEEE;
}
#nymfupzpof .gt_table_body {
border-top-style: none;
border-top-width: 2px;
border-top-color: #D3D3D3;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
}
#nymfupzpof .gt_footnotes {
color: #333333;
background-color: #FFFFFF;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
border-left-style: none;
border-left-width: 2px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 2px;
border-right-color: #D3D3D3;
}
#nymfupzpof .gt_footnote {
margin: 0px;
font-size: 90%;
padding-top: 4px;
padding-bottom: 4px;
padding-left: 5px;
padding-right: 5px;
}
#nymfupzpof .gt_sourcenotes {
color: #333333;
background-color: #FFFFFF;
border-bottom-style: none;
border-bottom-width: 2px;
border-bottom-color: #D3D3D3;
border-left-style: none;
border-left-width: 2px;
border-left-color: #D3D3D3;
border-right-style: none;
border-right-width: 2px;
border-right-color: #D3D3D3;
}
#nymfupzpof .gt_sourcenote {
font-size: 90%;
padding-top: 4px;
padding-bottom: 4px;
padding-left: 5px;
padding-right: 5px;
}
#nymfupzpof .gt_left {
text-align: left;
}
#nymfupzpof .gt_center {
text-align: center;
}
#nymfupzpof .gt_right {
text-align: right;
font-variant-numeric: tabular-nums;
}
#nymfupzpof .gt_font_normal {
font-weight: normal;
}
#nymfupzpof .gt_font_bold {
font-weight: bold;
}
#nymfupzpof .gt_font_italic {
font-style: italic;
}
#nymfupzpof .gt_super {
font-size: 65%;
}
#nymfupzpof .gt_footnote_marks {
font-size: 75%;
vertical-align: 0.4em;
position: initial;
}
#nymfupzpof .gt_asterisk {
font-size: 100%;
vertical-align: 0;
}
#nymfupzpof .gt_indent_1 {
text-indent: 5px;
}
#nymfupzpof .gt_indent_2 {
text-indent: 10px;
}
#nymfupzpof .gt_indent_3 {
text-indent: 15px;
}
#nymfupzpof .gt_indent_4 {
text-indent: 20px;
}
#nymfupzpof .gt_indent_5 {
text-indent: 25px;
}
#nymfupzpof .katex-display {
display: inline-flex !important;
margin-bottom: 0.75em !important;
}
#nymfupzpof div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
height: 0px !important;
}
</style>
  <table class="gt_table" style="table-layout: fixed;; width: 0px" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <colgroup>
    <col style="width:120px;" />
    <col style="width:120px;" />
    <col style="width:270px;" />
    <col style="width:120px;" />
    <col style="width:120px;" />
    <col style="width:270px;" />
    <col style="width:270px;" />
    <col style="width:270px;" />
    <col style="width:120px;" />
    <col style="width:270px;" />
    <col style="width:350px;" />
  </colgroup>
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="QRP">QRP</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Alias(es) &amp;amp; related concepts">Alias(es) &amp; related concepts</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Definition">Definition</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Umbrella term(s)">Umbrella term(s)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Research phase">Research phase</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Example(s)">Example(s)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Potential harms">Potential harms</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Preventive measures">Preventive measures</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Detectability">Detectability</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Clues">Clues</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="Sources">Sources</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">PARKing (preregistering after results are known)</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Preregistering a hypothesis or analysis after knowing the outcome of the analysis.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Misusing open science practices</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Planning</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher realizes that their paper won’t be accepted without a preregistration, so they create one post-hoc and link it to their study.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Be transparent about when the preregistration was done</li>
<li>Disclose the familiarity (if any) of the researcher with the data</li>
<li>Preregister before analyzing the data</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Data collection occurred previous to the preregistration date</li>
<li>Date of preregistration is unrealistically close to the first submission without the paper being a registered report</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Yamada, Y. (2018). How to crack pre-registration: toward transparent and Open Science. Frontiers in Psychology, 9, 1831. <a href="https://doi.org/10.3389/fpsyg.2018.01831">https://doi.org/10.3389/fpsyg.2018.01831</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Performing inappropriate power analysis</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selection of inappropriate parameters or methods for power analysis and/ or misinterpreting/misusing power analysis results.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Planning</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) A researcher chooses a small sample size to get null results in a study about the harmful effects of smoking.
(2) A researcher uses default parameters for the power analysis to show that power analysis had been performed, however, the analysis is uninformative.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
<li>Inflated type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Be transparent about how power analysis was conducted</li>
<li>Use meaningful parameters that are based on field standards, literature, or common sense</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Details of power analysis not reported or justified</li>
<li>Parameters of the power analysis are generic and do not fit the study</li>
<li>Relatively low sample size</li>
<li>The results of power analysis are misinterpreted</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Heckman, M. G., Davis, J. M., 3rd, &amp; Crowson, C. S. (2022). Post Hoc Power Calculations: An Inappropriate Method for Interpreting the Findings of a Research Study. The Journal of Rheumatology, 49(8), 867–870. <a href="https://doi.org/10.3899/jrheum.211115">https://doi.org/10.3899/jrheum.211115</a></li>
<li>Kovacs, M., van Ravenzwaaij, D., Hoekstra, R., &amp; Aczel, B. (2022). SampleSizePlanner: A Tool to Estimate and Justify Sample Size for Two-Group Studies. Advances in Methods and Practices in Psychological Science, 5(1), 25152459211054059. <a href="https://doi.org/10.1177/25152459211054059">https://doi.org/10.1177/25152459211054059</a></li>
<li>Lakens, D. (2022). Sample size justification. Collabra. Psychology, 8(1). <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Using biased manipulations</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Using an unjustified manipulation to reach a misleading outcome.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Influencing participants</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Planning</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Selecting sub-clinical drug doses to suggest no effect or only deliberately high does to suggest an adverse effect.
(2) Using images or videos to elicit emotions, but the stimuli are not eliciting emotions.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Run pilot studies to investigate if the manipulation can elicit an effect</li>
<li>Use manipulation check questions</li>
<li>Use standard stimuli or dosages</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Lack of manipulation check</li>
<li>Using dosages outside of recommended values</li>
<li>Using stimuli that can elicit extreme responses</li>
<li>Using stimuli that were not previously tested and/or have no proven effect</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Joe, S., &amp; Leif, N. (2020, March 10). Data Replicada #4: The Problem of Hidden Confounds. Data Colada. <a href="https://datacolada.org/85">https://datacolada.org/85</a></li>
<li>Marchetti, S., &amp; Schellens, J. H. M. (2007). The impact of FDA and EMEA guidelines on drug development in relation to Phase 0 trials. British Journal of Cancer, 97(5), 577–581. <a href="https://doi.org/10.1038/sj.bjc.6603925">https://doi.org/10.1038/sj.bjc.6603925</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Using measurement overlap to find significant results</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Leveraging the jangle fallacy</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Overestimating the magnitude of an effect that is largely due to measurement overlap of two seemingly distinct constructs.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Planning</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher is using similar items in two seemingly different constructs and concludes that the constructs have a high correlation.
(2) Researcher finds a positive relationship between depression and suicidality, but the positive relation is in part due to the depression scale already containing items about suicide.
(3) A researcher estimates a positive relation between construct A and construct B in a meta-analysis, but the meta-analysis includes studies that have used the same task to operationalize either construct.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Be transparent about similar items</li>
<li>Consider whether the measures used in a study distinctly operationalize different constructs</li>
<li>Account for covariance due to similar items</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Items or tasks are similar for the correlated constructs</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Flake, J. K., &amp; Fried, E. I. (2020). Measurement schmeasurement: Questionable measurement practices and how to avoid them. Advances in Methods and Practices in Psychological Science, 3(4), 456-465. <a href="https://doi.org/10.1177/2515245920952393">https://doi.org/10.1177/2515245920952393</a></li>
<li>Hodson, G. (2021). Construct jangle or construct mangle? Thinking straight about (nonredundant) psychological constructs. Journal of Theoretical Social Psychology, 5(4), 576–590. <a href="https://doi.org/10.1002/jts5.120">https://doi.org/10.1002/jts5.120</a></li>
<li>Wang, Y. A., &amp; Eastwick, P. W. (2020). Solutions to the problems of incremental validity testing in relationship science. Personal Relationships, 27(1), 156-175. <a href="https://doi.org/10.1111/pere.12309">https://doi.org/10.1111/pere.12309</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Using biased measurements</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Assessing a construct with an instrument that is biased or invalid, in order to support the desired narrative.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Influencing participants</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Planning</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher uses loaded, leading, or suggestive questions, e.g., “Does the lack of respect schoolchildren have for their teachers, in your opinion, influence everyday teaching methods in schools?”
(2) Researcher assesses a psychological construct using an ad hoc questionnaire with no proven validity.
(3) Researcher uses a scale that do not capture the intended construct properly in order to support a desired narrative</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Frame questions in a neutral way</li>
<li>Get external opinions on questionnaires/study materials OR conduct a registered report</li>
<li>Use questionnaires that are unbiased and psychometrically sound</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Ad hoc questionnaires are used instead of validated instruments
Measurement items use suggestive or biased language</li>
<li>Measurement is based on single-item questions</li>
<li>No discussion of the psychometric properties of the instruments</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Flake, J. K., &amp; Fried, E. I. (2020). Measurement Schmeasurement: Questionable Measurement Practices and How to Avoid Them. Advances in Methods and Practices in Psychological Science, 3(4), 456–465. <a href="https://doi.org/10.1177/2515245920952393">https://doi.org/10.1177/2515245920952393</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Optional stopping</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Peeking,
Data peeking</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Monitoring hypothesis tests during data collection, and stopping when statistical inference is favorable, without controlling for sequential testing.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Sample curation</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data collection</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher is collecting responses and tests the hypothesis after every participant - when significance is reached, the researcher stops collecting data.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated type I error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Preregister stopping rules and adjustments for type I error-inflation</li>
<li>Preregister the estimated sample size</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of preregistration</li>
<li>Low sample size</li>
<li>P-values are just below the significance threshold (usually 0.05)</li>
<li>Relatively large effect size compared to other studies in the field</li>
<li>Vague or absent reason for sample size</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>de Heide, R., &amp; Grünwald, P. D. (2021). Why optional stopping can be a problem for Bayesians. Psychonomic Bulletin &amp; Review, 28(3), 795–812. <a href="https://doi.org/10.3758/s13423-020-01803-x">https://doi.org/10.3758/s13423-020-01803-x</a></li>
<li>Lakens, D. (2022). Sample size justification. Collabra. Psychology, 8(1). <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a></li>
<li>Schönbrodt, F. D., &amp; Perugini, M. (2013). At what sample size do correlations stabilize? Journal of Research in Personality, 47(5), 609–612. <a href="https://doi.org/10.1016/j.jrp.2013.05.009">https://doi.org/10.1016/j.jrp.2013.05.009</a></li>
<li>Schönbrodt, F. D., Wagenmakers, E.-J., Zehetleitner, M., &amp; Perugini, M. (2017). Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences. Psychological Methods, 22, 322–339. doi:10.1037/met0000061 [OSF project with reproducible code, workshop slides, presentation slides]</li>
<li>Wicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., van Aert, R. C. M., &amp; van Assen, M. A. L. M. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832. <a href="https://doi.org/10.3389/fpsyg.2016.01832">https://doi.org/10.3389/fpsyg.2016.01832</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Retaining pilot data</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Double dipping</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Including data from a pilot study if the results support the hypothesis.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Sample curation</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Data collection</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher conducts a pilot study to check the protocol and analyzes pilot data. The pilot data and main study data are aggregated in the data analysis if pilot data results are in line with expectations.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Don’t include pilot data in the analyzed dataset</li>
<li>Report pilot data separately</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>If data are shared, timestamps may fall into two distinct periods</li>
<li>Sample sizes reported throughout the paper might not match</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Kravitz, D., &amp; Mitroff, S. (2020). Quantifying, and correcting for, the impact of questionable research practices on false discovery rates in psychological science. <a href="https://doi.org/10.31234/osf.io/fu9gy">https://doi.org/10.31234/osf.io/fu9gy</a></li>
<li>Kriegeskorte, N., Simmons, W. K., Bellgowan, P. S. F., &amp; Baker, C. I. (2010). Circular analysis in systems neuroscience the dangers of double dipping. Nature Neuroscience, 12(5), 535–540. <a href="https://doi.org/10.1038/nn.2303">https://doi.org/10.1038/nn.2303</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selective sampling</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Biased sampling</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Choosing a sample in a way that biases the findings.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Sample curation</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data collection</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher tests the likeability of chocolate on a group of children only in order to find that everyone loves it.
(2) Using uncomparable groups: The researcher tests if men are more aggressive than women. For comparison, women from a university are compared with men from a prison.
(3) Picking a subsample of a panel dataset to find the desired results.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability if sampling bias is not disclosed</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Consider using statistical control for confounding variables</li>
<li>Make sure that the sample represents the population</li>
<li>Preregister the sampling process</li>
<li>Report the sampling process transparently</li>
<li>Use a sampling method that doesn’t bias the results</li>
<li>Use comparable (or matched) groups</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Compared groups are from different populations</li>
<li>Convenience sample</li>
<li>Unclear rationale for sample selection</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>DeepChecks. (n.d.). Selective Sampling. deepchecks.com. Retrieved May 15, 2023, from <a href="https://deepchecks.com/glossary/selective-sampling/">https://deepchecks.com/glossary/selective-sampling/</a></li>
<li>Marks, E. S. (1947). Selective sampling in psychological research. Psychological Bulletin, 44(3), 267–275. <a href="https://doi.org/10.1037/h0061812">https://doi.org/10.1037/h0061812</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Grooming participants</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Affecting participants to make them give responses that support the desired narrative.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Influencing participants</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Data collection</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1)     Researcher tells the participants that he believes the treatment will work.
(2)     Researcher uses a briefing document that is trying to influence participants’ attitudes about the topic that is assessed in the study.
(3)     During data collection the same organization that runs the study also runs a marketing campaign to influence public opinion on the same topic.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Avoid exposing participants to any cues that might influence their responses</li>
<li>Blind the experimenter where possible</li>
<li>Researchers interacting with participants should remain neutral and follow scripts during testing</li>
<li>Use automated research procedures (e.g. research presentation software) instead of human research assistants wherever possible</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">No</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of blinding</li>
<li>Absence of procedure scripts</li>
<li>Suggestive questions in the survey</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>McCambridge, J., de Bruin, M., &amp; Witton, J. (2012). The effects of demand characteristics on research participant behaviours in non-laboratory settings: a systematic review. PloS One, 7(6), e39116. <a href="https://doi.org/10.1371/journal.pone.0039116">https://doi.org/10.1371/journal.pone.0039116</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Excluding data points</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Exclusion of data points or outliers without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Removing individual reaction time trials based on post hoc criteria.
(2) Trying different outlier cut-off criteria until an effect is statistically significant.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister the study</li>
<li>Report post hoc changes in exclusion criteria</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Absence of preregistration</li>
<li>Unexplained discrepancy between the recruited and analyzed sample sizes and degrees of freedom</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of psychological research. PloS one, 9(7), e103360. <a href="https://doi.org/10.1371/journal.pone.0103360">https://doi.org/10.1371/journal.pone.0103360</a></li>
<li>Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal, sum scores, and the inflation of the Type I error rate in independent samples t tests: the power of alternatives and recommendations. Psychological Methods, 19(3), 409–427. <a href="https://doi.org/10.1037/met0000014">https://doi.org/10.1037/met0000014</a></li>
<li>Osborne, J. W., &amp; Overbay, A. (2004). The power of outliers (and why researchers should always check for them). Practical Assessment, Research, and Evaluation, 9(1), 6. <a href="https://doi.org/10.7275/qf69-7k43">https://doi.org/10.7275/qf69-7k43</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Missing data hacking</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Favorable imputation</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Choosing the strategy to handle missing data based on the impact on the results.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1)     A researcher tries three ways of handling missing data, for example, listwise deletion, multiple imputation, and inverse probability weighting. The expected results only appear with inverse probability weighting. The researcher reports only this strategy in the paper and leaves out results with listwise deletion and multiple imputation.
(2)     Can also be within a single method, specifically multiple imputation, since it uses one or more variables to replace missing data, and the choice of these variables is up to the researcher, but can also be statistically based.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced reproducibility</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister missing data approach</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Lack of rationale or references supporting the missing data approach</li>
<li>No mention of the missing data approach or the missing data at all</li>
<li>Unexplained discrepancy between the recruited and analyzed sample sizes</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Enders, C. K. (2010). Applied missing data analysis. Guilford Press.</li>
<li>Woods, A. D., Gerasimova, D., Van Dusen, B., Nissen, J., Bainter, S., Uzdavines, A., Davis-Kean, P. E., Halvorson, M., King, K. M., Logan, J. A. R., Xu, M., Vasilev, M. R., Clay, J. M., Moreau, D., Joyal-Desmarais, K., Cruz, R. A., Brown, D. M. Y., Schmidt, K., &amp; Elsherif, M. M. (2023). Best practices for addressing missing data through multiple imputation. Infant and Child Development. <a href="https://doi.org/10.1002/icd.2407">https://doi.org/10.1002/icd.2407</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Using ad hoc exclusion criteria for participants</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Exclusion of participants without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking
Sample curation</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher finds that a correlation between two variables is not significant. After removing two participants - who should be included - the association becomes significant. Then the researcher comes up with post hoc exclusion criteria for those participants.
(2) A researcher doesn’t find an expected association between perceived stress and personality. When looking only at the top 25% of perceived stress scores, the association is there. They go on to report the top 25% scores as their population of interest and do not disclose that they looked at the rest of the sample population.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister the study</li>
<li>Report post hoc changes in exclusion criteria</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Absence of preregistration</li>
<li>Sample too narrow for recruitment methods</li>
<li>Unexplained discrepancy between the recruited and analyzed sample sizes</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Lang, S., Armstrong, N., Deshpande, S., Ramaekers, B., Grimm, S., de Kock, S., Kleijnen, J., &amp; Westwood, M. (2019). Clinically inappropriate post hoc exclusion of study participants from test accuracy calculations: the ROMA score, an example from a recent NICE diagnostic assessment. Annals of clinical biochemistry, 56(1), 72–81. <a href="https://doi.org/10.1177/0004563218782722">https://doi.org/10.1177/0004563218782722</a></li>
<li>Nüesch, E., Trelle, S., Reichenbach, S., Rutjes, A. W. S., Bürgi, E., Scherer, M., Altman, D. G., &amp; Jüni, P. (2009). The effects of excluding patients from the analysis in randomised controlled trials: meta-epidemiological study. BMJ (Clinical Research Ed.), 339(sep07 1), b3244. <a href="https://doi.org/10.1136/bmj.b3244">https://doi.org/10.1136/bmj.b3244</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Discretizing continuous variables</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Dichotimizing variables,
Median split</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Taking a continuous variable and making it categorical without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1)     Researcher doesn’t find an association between depression and continuous age variables, and recodes age into young and old categories. After that, age groups show a significant association with depression. An independent samples t-test is reported instead of a correlation.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
<li>Reduced generalizability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister the study</li>
<li>Use original measurement levels</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Scale or response options in materials or methods do not match how they are reported in the results</li>
<li>Test statistics do not match expected data analysis strategy</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Cohen, J. (1983). The cost of dichotomization. Applied Psychological Measurement, 7, 247-253. <a href="https://doi.org/10.1177/014662168300700301">https://doi.org/10.1177/014662168300700301</a></li>
<li>DeCoster, J., Gallucci, M., &amp; Iselin, A.-M. R. (2011). Best practices for using median splits, artificial categorization, and their continuous alternatives. Journal of Experimental Psychopathology, 2(2), 197–209. <a href="https://doi.org/10.5127/jep.008310">https://doi.org/10.5127/jep.008310</a></li>
<li>MacCallum, R. C., Zhang, S., Preacher, K. J., &amp; Rucker, D. D. (2002). On the practice of dichotomization of quantitative variables. Psychological Methods, 7(1), 19–40. <a href="https://doi.org/10.1037/1082-989X.7.1.19">https://doi.org/10.1037/1082-989X.7.1.19</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Modifying measurements</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Changing the properties of a measure/measurement to produce favorable results without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher uses only a portion of the items from a longer scale.
(2) Researcher combines items from different scales into a single measure.
(3) Researcher chooses which EEG electrodes to aggregate based on the results.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
<li>Reduced validity of the measure</li>
<li>Inflated or deflated reliability of the measure</li>
<li>Inflated type I or type II error</li>
<li>Inflated or deflated effect size estimates</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Describe and justify any modifications on measurements</li>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Publish study materials</li>
<li>Preregister the study</li>
<li>Use conventional measurements/measures</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Absence of open study materials</li>
<li>Discrepancy between the reported version of measurement/measure and original or conventional measure</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Flake, J. K., &amp; Fried, E. I. (2020). Measurement schmeasurement: Questionable measurement practices and how to avoid them. Advances in Methods and Practices in Psychological Science, 3(4), 456-465. <a href="https://doi.org/10.1177/2515245920952393">https://doi.org/10.1177/2515245920952393</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Redefining group membership rules</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Post hoc (re)definition of grouping criteria without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Collapsing the multicategorical variable of sexual orientation into heterosexual and non-heterosexual.
(2) Trying different age ranges in cross-sectional age comparisons to maximize group differences.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
<li>Reduced generalizability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Report post hoc changes in grouping rules and report results using original grouping rules as well</li>
<li>Preregister the study</li>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Absence of preregistration</li>
<li>Oversimplified sample description</li>
<li>Response options in materials/methods different than reported groups</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., &amp; Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 1832. <a href="https://doi.org/10.3389/fpsyg.2016.0183">https://doi.org/10.3389/fpsyg.2016.0183</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Variable transformation fishing</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selecting variable transformations that produce favorable results without proper justification and transparent reporting.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Data processing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher runs a statistical test using several different transformations (e.g., changing levels of measurement, log-transformations, rescaling) of the outcome, and only reports the one that produces a significant result.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Describe and justify any variable transformations</li>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister conditional transformations</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Abscence of open data</li>
<li>Reported values are outside of regular range</li>
<li>Transformation is applied without justification</li>
<li>Using transformations that are unconventional for the measure</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Lee, D. K. (2020). Data transformation: a focus on the interpretation. Korean Journal of Anesthesiology, 73(6), 503–508. <a href="https://doi.org/10.4097/kja.20137">https://doi.org/10.4097/kja.20137</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Choosing a poor model specification</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Overfitting or underfitting models,
Bias-variance tradeoff</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Creating too complex models on too small datasets causing the model to learn the noise and random fluctuations instead of generalizable patterns. Alternatively, creating too simple models that do not adequately fit the data.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1)     Overfitting: The researcher fits a regression model with 25 predictors on a sample of 100 participants.
(2)     Underfitting: The researcher uses linear regression to investigate a non-linear association.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Use a theoretically justified model in confirmatory studies</li>
<li>Underfitting: Visualize data and the model</li>
<li>Use methods that prevent overfitting in exploratory research, e.g. use separate train and test datasets, use cross-validation resampling methods, use regularization or other feature selection methods</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Improper prediction selection (e.g., no regularization)</li>
<li>No mention of holdout (or test) dataset or cross-validation</li>
<li>Overfitting: Very high R2 value (close to 1)</li>
<li>The number of included predictors in the model is large</li>
<li>The number of observations is low</li>
<li>Underfitting: Data visualization shows high model bias</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Babyak, M. A. (2004). What you see may not be what you get: a brief, nontechnical introduction to overfitting in regression-type models. Psychosomatic medicine, 66(3), 411-421.</li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Choosing unjustified p-value adjustment</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Not adjusting or over-adjusting p-values</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Not adjusting or over-adjusting p-values when running multiple tests.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">A researcher decides (1) whether or not to adjust for multiple tests (e.g., in an ANOVA) and (2) which adjustment method to use, and (3) which (i.e. how many) comparisons to include depending on results obtained.
(4) Researcher uses Bonferroni correction when correlating several variables, to prove that an association does not exist.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated type I or type II error</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform sensitivity analysis</li>
<li>Preregister p-value adjustment plans</li>
<li>Preregister planned contrasts</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Multiple tests are made that would require p-value adjustment</li>
<li>P-value adjustment not mentioned</li>
<li>Using p-value correction that is too strict (e.g., Bonferroni) without proper justification</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Bender, R., &amp; Lange, S. (2001). Adjusting for multiple testing—when and how?. Journal of clinical epidemiology, 54(4), 343-349. <a href="https://doi.org/10.1016/S0895-4356(00)00314-0">https://doi.org/10.1016/S0895-4356(00)00314-0</a></li>
<li>Cramer, A. O., van Ravenzwaaij, D., Matzke, D., Steingroever, H., Wetzels, R., Grasman, R. P., … &amp; Wagenmakers, E. J. (2016). Hidden multiplicity in exploratory multiway ANOVA: Prevalence and remedies. Psychonomic bulletin &amp; review, 23(2), 640-647.  <a href="https://doi.org/10.3758/s13423-015-0913-5">https://doi.org/10.3758/s13423-015-0913-5</a></li>
<li>Midway, S., Robertson, M., Flinn, S., &amp; Kaller, M. (2020). Comparing multiple comparisons: practical guidance for choosing the best multiple comparisons test. PeerJ, 8, e10387. <a href="https://doi.org/10.7717/peerj.10387">https://doi.org/10.7717/peerj.10387</a>.</li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Neglecting assumptions for statistical models</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Using statistical models although requirements are not met.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Analyzing data, using parametric tests such as t-tests but the data requires a non-parametric test.
(2) Analyzing dependent data using a statistical model that does not account for dependency.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform and report necessary assumption checks</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Evidence of assumption breaches (e.g., non-normality, non-independent data, largely different SDs by group)</li>
<li>Not reporting assumption checks</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Knief, U., &amp; Forstmeier, W. (2021). Violating the normality assumption may be the lesser of two evils. Behavior Research Methods, 53(6), 2576-2590. <a href="https://doi.org/10.3758/s13428-021-01587-5">https://doi.org/10.3758/s13428-021-01587-5</a></li>
<li>Meteyard, L., &amp; Davies, R. A. (2020). Best practice guidance for linear mixed-effects models in psychological science. Journal of Memory and Language, 112, 104092. <a href="https://doi.org/10.1016/j.jml.2020.104092">https://doi.org/10.1016/j.jml.2020.104092</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Using ad hoc covariates</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Selectively including control variables</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Addition or removal of covariates to influence the estimates or significance for the effect of interest.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) A researcher opportunistically decides which background variables (e.g., age, gender) to control for, without a causal theory or a preregistration.
(2) A researcher decides whether to control for a baseline value in an experimental design depending on the results of statistical tests.
(3) Researcher avoids the inclusion (or measurement) of theoretically justified moderators (e.g., severity of a condition, or socio-economic status) to be able to imply greater generalisability.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Preregister complete models/analytical plan</li>
<li>Report robustness checks</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Different covariates in different analysis steps are used</li>
<li>There is a lack of justification for the selection of the covariates</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Becker, T. E., Atinc, G., Breaugh, J. A., Carlson, K. D., Edwards, J. R., &amp; Spector, P. E. (2016). Statistical control in correlational studies: 10 essential recommendations for organizational researchers. Journal of Organizational Behavior, 37(2), 157-167. <a href="https://doi.org/10.1002/job.2053">https://doi.org/10.1002/job.2053</a></li>
<li>Stefan, A., &amp; Schönbrodt, F. D. (2022, March 16). Big little lies: A compendium and simulation of p-hacking strategies. <a href="https://doi.org/10.31234/osf.io/xy2dk">https://doi.org/10.31234/osf.io/xy2dk</a></li>
<li>VanderWeele, T. J. (2019). Principles of confounder selection. European journal of epidemiology, 34(3), 211-219. <a href="https://doi.org/10.1007/s10654-019-00494-6">https://doi.org/10.1007/s10654-019-00494-6</a></li>
<li>Wysocki, A. C., Lawson, K. M., &amp; Rhemtulla, M. (2022). Statistical control requires causal justification. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221095823. <a href="https://doi.org/10.1177/25152459221095823">https://doi.org/10.1177/25152459221095823</a>.</li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Selecting a favorable random number generator seed</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Resampling lottery</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Trying different random seeds until getting a favorable result, potentially in combination with small number of replications</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">P-hacking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) A researcher keeps on bootstrapping a confidence interval (e.g., for a mediation indirect effect) with different seeds until the 95% confidence interval just excludes 0.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Only report significance if the results are robust across random seeds</li>
<li>Use a large number of replications (e.g., bootstrap samples)</li>
<li>Perform blinded data analysis</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>P-values just below the significance threshold (usually 0.05)</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Götz, M., O’Boyle, E. H., Gonzalez-Mulé, E., Banks, G. C., &amp; Bollmann, S. S. (2021). The “Goldilocks Zone”: (Too) many confidence intervals in tests of mediation just exclude zero. Psychological Bulletin, 147(1), 95–114. <a href="https://doi.org/10.1037/bul0000315">https://doi.org/10.1037/bul0000315</a></li>
<li>Stack Exchange. (2018). Choosing the “correct” seed for reproducible research/results. Cross Validated. Retrieved January 10, 2023, from <a href="https://stats.stackexchange.com/questions/335936/choosing-the-correct-seed-for-reproducible-research-results">https://stats.stackexchange.com/questions/335936/choosing-the-correct-seed-for-reproducible-research-results</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selective test reporting</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Repeatedly testing a hypothesis in different ways until the desired result is found, and then selectively reporting the findings that support the desired conclusion.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">P-hacking
Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Hypothesis testing</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Researcher analyzes the data using (1) multiple statistical methods (multiple t-tests, ANOVAs, different random structures in LMEMs) and/ or (2) multiple data eligibility specifications. Based on the results, they choose to present only one analysis that gives a significant result.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
<li>Inflated type I or type II error</li>
<li>Reduced reproducibility</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Perform specificity curve analysis</li>
<li>Preregister data processing (e.g., missing data approach) and statistical analysis strategy</li>
<li>Report all performed hypothesis-tests</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of preregistration</li>
<li>Arbitrary data processing steps and/or statistical methods</li>
<li>P-values just below the significance threshold (usually 0.05)</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Chuard, P. J. C., Vrtílek, M., Head, M. L., &amp; Jennions, M. D. (2019). Evidence that nonsignificant results are sometimes preferred: Reverse P-hacking or selective reporting? PLoS Biology, 17(1), e3000127. <a href="https://doi.org/10.1371/journal.pbio.3000127">https://doi.org/10.1371/journal.pbio.3000127</a></li>
<li>Head, M. L., Holman, L., Lanfear, R., Kahn, A. T., &amp; Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biology, 13(3), e1002106. <a href="https://doi.org/10.1371/journal.pbio.1002106">https://doi.org/10.1371/journal.pbio.1002106</a></li>
<li>Olejnik, S. F., &amp; Algina, J. (1987). Type I error rates and power estimates of selected parametric and nonparametric tests of scale. Journal of Educational Statistics, 12(1), 45-61.  <a href="https://doi.org/10.3102/10769986012001045">https://doi.org/10.3102/10769986012001045</a></li>
<li>Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a></li>
<li>Wagenmakers, EJ. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin &amp; Review 14, 779–804. <a href="https://doi.org/10.3758/BF03194105">https://doi.org/10.3758/BF03194105</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">HARKing (hypothesizing after the results are known)</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Texas sharpshooter fallacy,
Post hoc ergo propter hoc</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Presenting a hypothesis that is based on observed results (post-hoc or a posteriori) as if it was presumed before obtaining results (a priori).</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher claims to have predicted an unexpected result.
(2) Researcher has no hypotheses originally and forms hypotheses after exploring the data and presenting the hypotheses as they had those from the beginning.
(3) Researcher has a hypothesis (e.g., a mediation hypothesis) and tests it, and if the results do not confirm the hypothesis but rather indicate an alternative pattern (e.g., a moderation), the researcher claims that this is what they hypothesized all along.
(4) Post-hoc directional hypotheses: The researcher presents a hypothesis as if it was uni-directional (i.e. group A’s mean is larger than group B’s, or a correlation will be positive), although the original hypothesis was bi-directional. This change will make the hypothesis test significant.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Clearly separate exploratory and confirmatory findings</li>
<li>Form hypotheses before analyzing the data</li>
<li>Perform blinded data analysis</li>
<li>Preregister confirmatory hypotheses</li>
<li>Use robust exploratory research practices (e.g. holdout dataset, cross-validation, multiverse analysis, blinded data analysis, etc.)</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of preregistration</li>
<li>Unexplained and unconventional choices in the methods and results section</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Andrade, C. (2021). HARKing, Cherry-Picking, P-Hacking, Fishing Expeditions, and Data Dredging and Mining as Questionable Research Practices. The Journal of Clinical Psychiatry, 82(1). <a href="https://doi.org/10.4088/JCP.20f13804">https://doi.org/10.4088/JCP.20f13804</a></li>
<li>Brookes, S.T., Whitley, E., Peters, T.J., Mulheran, P.A., Egger, M. &amp; Davey Smith, G. (2001). Subgroup analysis in randomised controlled trials: Quantifying the risks of false-positives and false-negatives, Health Technology Assessment, 5(33), 1–56. <a href="https://doi.org/10.3310/hta5330">https://doi.org/10.3310/hta5330</a></li>
<li>Kerr, N. L. (1998). HARKing: hypothesizing after the results are known. Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc, 2(3), 196–217. <a href="https://doi.org/10.1207/s15327957pspr0203_4">https://doi.org/10.1207/s15327957pspr0203_4</a></li>
<li>Leung, K. (2011). Presenting post hoc hypotheses as a priori: Ethical and theoretical issues. Management and Organization Review, 7(3), 471–479. <a href="https://doi.org/10.1111/j.1740-8784.2011.00222.x">https://doi.org/10.1111/j.1740-8784.2011.00222.x</a></li>
<li>Weston, S. J., Ritchie, S. J., Rohrer, J. M., &amp; Przybylski, A. K. (2019). Recommendations for increasing the transparency of analysis of preexisting data sets. Advances in Methods and Practices in Psychological Science, 2(3), 214–227. <a href="https://doi.org/10.1177/2515245919848684">https://doi.org/10.1177/2515245919848684</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Making unsupported conclusions</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Interpreting research findings or their implications in a way that is not backed by evidence.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher concludes that a treatment is effective for groups and contexts that were not considered in the study.
(2) Researcher concludes that a treatment worked, however, the treatment effect did not differ from the effect of the control condition (or no control condition was used).
(3) Researcher implies causality based on a research design or that does not allow causal inference.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;">NA</td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Make it clear that the evidence is limited to certain contexts</li>
<li>Make sure that every interpretation is properly supported by evidence</li>
<li>Use conditional statements where evidence is weak or the researcher uses extrapolation</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Causal claims are made without the methodology or analysis allowing causal inference</li>
<li>Results are generalized to contexts outside of the study’s scope</li>
<li>The chosen methodology and statistical analysis do not allow to answer the hypothesis</li>
<li>The statistical results do not match the conclusions</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Simons, D. J., Shoda, Y., &amp; Lindsay, D. S. (2017). Constraints on Generality (COG): A proposed addition to all empirical papers. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 12(6), 1123–1128. <a href="https://doi.org/10.1177/1745691617708630">https://doi.org/10.1177/1745691617708630</a></li>
<li>Yarkoni, T. (2020). The generalizability crisis. The Behavioral and Brain Sciences, 45, e1. <a href="https://doi.org/10.1017/S0140525X20001685">https://doi.org/10.1017/S0140525X20001685</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Incorrect reporting of test statistics</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Not using statistical test reporting conventions to obscure exact results and assume that they are above or below threshold values.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1)     Researcher is ‘rounding off’ a p-value in a paper (e.g., reporting that a p-value of .054 is less or equal to .05).
(2)     Researcher reports p-values only and conceals test statistics.
(3)     Researcher reports a correlation without disclosing the degrees of freedom, number of observations, or confidence interval, so it seems like the effect is large (for example r=.70, n=15, CI=[.01; .90]).
(4)     Researcher does a model comparison and only reports fit statistics that are in favor of the preferred model.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated type I or type II error</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Adhere to reporting conventions (e.g., APA)</li>
<li>Publish data</li>
<li>Publish processing and analysis code</li>
<li>Use literate programming (e.g., RMarkdown, quarto, jupyter)</li>
<li>Work with software that supports you in producing and checking your write-up (e.g., papaja, stat-check)</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open code</li>
<li>Absence of open data</li>
<li>Anomalies in reported statistics, e.g., test statistics are incompatible with p-values</li>
<li>Fit statistics are missing without proper explanation</li>
<li>Statistics are not reported according to conventions (e.g., three digits for p-values, reporting of df)</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43(3), 666–678. <a href="https://doi.org/10.3758/s13428-011-0089-5">https://doi.org/10.3758/s13428-011-0089-5</a></li>
<li>Jackson, D. L., Gillaspy, J. A., &amp; Purc-Stephenson, R. (2009). Reporting practices in confirmatory factor analysis: an overview and some recommendations. Psychological Methods, 14(1), 6–23. <a href="https://doi.org/10.1037/a0014694">https://doi.org/10.1037/a0014694</a></li>
<li>Nuijten, Michèle B., Hartgerink, C. H. J., van Assen, M. A. L. M., Epskamp, S., &amp; Wicherts, J. M. (2016). The prevalence of statistical reporting errors in psychology (1985–2013). Behavior Research Methods, 48(4), 1205–1226. <a href="https://doi.org/10.3758/s13428-015-0664-2">https://doi.org/10.3758/s13428-015-0664-2</a></li>
<li>Nuijten, Michele B., van Assen, M. A. L. M., Hartgerink, C. H. J., Epskamp, S., &amp; Wicherts, J. M. (2017). The validity of the tool “statcheck” in discovering statistical reporting inconsistencies. In PsyArXiv. <a href="https://doi.org/10.31234/osf.io/tcxaj">https://doi.org/10.31234/osf.io/tcxaj</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Omitting important details of the scientific process</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Incomplete methods or results section</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Not reporting important details of the methodology and statistical analysis.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher omits sample characteristics.
(2) Researcher reports correlations without specifying the type, e.g., Spearman.
(3) Researcher reports having conducted an online study and does not reveal it was an MTurk-study.
(4) Researcher does not fully disclose compensation etc. for participants during data collection.
(5) Researcher does not share study materials on request.
(6) Researcher does not report exact questionnaire items.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Preregister the study or written research plan before conducting the study</li>
<li>Report every important detail of the scientific process</li>
<li>Use a lab log during data collection to keep track of changes in the scientific process</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open study materials</li>
<li>Details that are usually shared are missing</li>
<li>Replication is not possible from published methods</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Gernsbacher, M. A. (2018). Writing Empirical Articles: Transparency, Reproducibility, Clarity, and Memorability. Advances in Methods and Practices in Psychological Science, 1(3), 403–414. <a href="https://doi.org/10.1177/2515245918754485">https://doi.org/10.1177/2515245918754485</a></li>
<li>National Academies of Sciences, Engineering, and Medicine, Policy and Global Affairs, Committee on Science, Engineering, Medicine, and Public Policy, Board on Research Data and Information, Division on Engineering and Physical Sciences, Committee on Applied and Theoretical Statistics, Board on Mathematical Sciences and Analytics, Division on Earth and Life Studies, Nuclear and Radiation Studies Board, &amp; Division of Behavioral and Social Sciences and Education. (2019). Reproducibility and Replicability in Science. National Academies Press.</li>
<li>Wagenmakers, E.-J., Sarafoglou, A., Aarts, S., Albers, C., Algermissen, J., Bahník, Š., van Dongen, N., Hoekstra, R., Moreau, D., van Ravenzwaaij, D., Sluga, A., Stanke, F., Tendeiro, J., &amp; Aczel, B. (2021). Seven steps toward more transparency in statistical practice. Nature Human Behaviour, 5(11), 1473–1480. <a href="https://doi.org/10.1038/s41562-021-01211-8">https://doi.org/10.1038/s41562-021-01211-8</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Selective reporting of hypotheses</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Cherry-picking hypotheses,
Chrysalis effect,
Fishing expedition</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Reporting hypothesis test only if it fits the researcher&#39;s expectation.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher formulates five hypotheses of which only three are supported by the data - only these 3 get reported in the final research report (Chrysalis effect).
(2) Fishing expedition - The researcher surveys college students about the outfit they are wearing and their scores on several tests which allows for many possible analyses (examining different colors, types of clothing, tests, score cutoffs, etc.). They end up reporting only a subset of findings to claim college students perform significantly better on tests when they are wearing green. See also Modifying measurement, Selective reporting of indicator variables, and Selective reporting of outcomes.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>If some hypotheses get left out due to the scope of the write-up be transparent about it</li>
<li>Preregister the study</li>
<li>Report all hypotheses in the write-up regardless of whether they were confirmed or not</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Number of hypotheses in preregistration (or dissertation) exceeds the number in the publication</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Andrade C (2021). HARKing, cherry-picking, P-hacking, fishing expeditions, and data dredging and mining as questionable research practices. Journal of Clinical Psychiatry , 82(1), 20f13804. <a href="https://doi.org/10.4088/JCP.20f13804">https://doi.org/10.4088/JCP.20f13804</a></li>
<li>O’Boyle, E. H., Jr, Banks, G. C., &amp; Gonzalez-Mulé, E. (2017). The Chrysalis Effect: How ugly initial results metamorphosize into beautiful articles. Journal of Management, 43(2), 376–399. <a href="https://doi.org/10.1177/0149206314527133">https://doi.org/10.1177/0149206314527133</a></li>
<li>Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Visualizing data in a misleading way</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Choosing suboptimal visualizations or altering figure properties in order to exaggerate or diminish effects.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher truncates the y-axis so it is not starting at zero and/or does not add error bars. This makes differences seem larger and more significant than they are in reality.
(2) Researcher uses arbitrary categories to present interval data on a map.
(3) Researcher displays a pie chart with percentage numbers falling below or exceeding 100.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;">NA</td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Follow best practices on how to visualize data</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Chartjunk (e.g., 3D elements, ornaments) is present on the plot</li>
<li>In a plot y-axis is starting at an arbitrary point</li>
<li>Only summary statistics are shown without individual data points</li>
<li>Scale or response options in text do not match how they are presented in a plot</li>
<li>Statistical uncertainty (e.g., error bars) is not shown on plots</li>
<li>Visualization does not match the reported results in the text</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Nguyen, V. T., Jung, K., &amp; Gupta, V. (2021). Examining data visualization pitfalls in scientific publications. Visual Computing for Industry, Biomedicine, and Art, 4(1), 27. <a href="https://doi.org/10.1186/s42492-021-00092-y">https://doi.org/10.1186/s42492-021-00092-y</a></li>
<li>Weissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S., Garcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., &amp; Milic, N. M. (2019). Reveal, don’t conceal: Transforming data visualization to improve transparency. Circulation, 140(18), 1506–1518. <a href="https://doi.org/10.1161/circulationaha.118.037777">https://doi.org/10.1161/circulationaha.118.037777</a></li>
<li>Wilke, C. O. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures (1st ed.). O’Reilly Media.</li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Citing unreliable research</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Citing an unreliable publication to support the study&#39;s narrative.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Citation engineering</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher cites a publication that presents low-level evidence to support a claim with no reference to the study’s limitations or no reference to other studies.
(2) The researcher cites a retracted paper.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Increasing the credibility of low-evidence research</li>
<li>Inflated credibility of statements</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Never cite a retracted study</li>
<li>Only cite publications that properly support their claims</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>The cited publication provides no or low-quality evidence to its claims</li>
<li>The cited publication is retracted or otherwise discredited or its claims are refuted</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Balshem, H., Helfand, M., Schünemann, H. J., Oxman, A. D., Kunz, R., Brozek, J., Vist, G. E., Falck-Ytter, Y., Meerpohl, J., Norris, S., &amp; Guyatt, G. H. (2011). GRADE guidelines: 3. Rating the quality of evidence. Journal of Clinical Epidemiology, 64(4), 401–406. <a href="https://doi.org/10.1016/j.jclinepi.2010.07.015">https://doi.org/10.1016/j.jclinepi.2010.07.015</a></li>
<li>Letrud, K., &amp; Hernes, S. (2019). Affirmative citation bias in scientific myth debunking: A three-in-one case study. PLOS ONE, 14(9), e0222213. <a href="https://doi.org/10.1371/journal.pone.0222213">https://doi.org/10.1371/journal.pone.0222213</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selective reporting of indicator variables</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Cherry-picking indicator variables,
Cherry-picking conditions/ groups</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Reporting only the indicator variables (or predictors, features, independent variables) that are used in analyses that produce expected results.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher reports IVs that are associated with the outcome rather than including all measured IVs in the results section.
(2) Researcher drops one or more conditions or groups/merges two or more groups into one / splits a group into more groups than were initially planned depending on statistical results.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Preregister the study</li>
<li>Report all indicators</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Indicators reported in Supplemental Material but not mentioned in main text</li>
<li>Measures get reported in the methods section but not in the results section</li>
<li>Number of preregistered indicators exceeds the number of indicators in publication</li>
<li>Reported mean time of participation does not match the number of reported measures</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Gernsbacher, M. A. (2018). Writing empirical articles: Transparency, reproducibility, clarity, and memorability. Advances in Methods and Practices in Psychological Science, 1(3), 403–414. <a href="https://doi.org/10.1177/2515245918754485">https://doi.org/10.1177/2515245918754485</a></li>
<li>Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Selective reporting of outcomes</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Cherry-picking outcomes</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Reporting only the outcomes (or dependent variables) that are used in analyses that produce expected results.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher uses several scales to measure the same construct but only reports the one that produces expected results.
(2) Researcher tests effectiveness of a new intervention for depression by measuring its effects on anxiety, sleep quality, and stress and only reports the outcome that shows the desired effect.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated or deflated effect size estimates</li>
<li>Inflated type I or type II error</li>
<li>Reduced generalizability</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Perform blinded data analysis</li>
<li>Preregister the study</li>
<li>Report all outcomes</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Measures get reported in the methods section but not in the results section</li>
<li>Number of preregistered outcomes exceeds number outcomes in publication</li>
<li>Outcomes reported in Supplemental Material but not mentioned in main text</li>
<li>Reported mean time of participation does not match number of reported measures</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Gernsbacher, M. A. (2018). Writing Empirical Articles: Transparency, Reproducibility, Clarity, and Memorability. Advances in Methods and Practices in Psychological Science, 1(3), 403–414. <a href="https://doi.org/10.1177/2515245918754485">https://doi.org/10.1177/2515245918754485</a></li>
<li>Pigott, T. D., Valentine, J. C., Polanin, J. R., Williams, R. T., &amp; Canada, D. D. (2013). Outcome-reporting bias in education research. Educational Researcher, 42(8), 424–432. <a href="https://doi.org/10.3102/0013189X13507104">https://doi.org/10.3102/0013189X13507104</a></li>
<li>Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Using unjustified references</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selectively citing works by specific researchers or journals to inflate citation metrics or boost a journal’s impact factor.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Citation engineering</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher selectively cites their own publications for boosted citation metrics.
(2) Citation networks: Researcher cites a colleague’s unrelated work in order to get cited in a similar way.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated credibility of publications</li>
<li>Inflated credibility of journals</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Cite only relevant studies</li>
<li>Provide comprehensive coverage of related scholarly literature</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Publications are cited without relevance to the claims</li>
<li>Specific authors or journals are cited disproportionately frequently</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Fong, E. A., &amp; Wilhite, A. W. (2017). Authorship and citation manipulation in academic research. PloS One, 12(12), e0187394. <a href="https://doi.org/10.1371/journal.pone.0187394">https://doi.org/10.1371/journal.pone.0187394</a></li>
<li>Mehregan, M. (2022). Scientific journals must be alert to potential manipulation in citations and referencing. Research Ethics, 18(2), 163–168. <a href="https://doi.org/10.1177/17470161211068745">https://doi.org/10.1177/17470161211068745</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Not disclosing deviations from preregistration</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Deviating from the preregistration without transparency and proper justification in the publication.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Misusing open science practices</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher preregisters that they would collect data from a non-student sample, but ends up including students, and does not disclose this deviation.
(2) Researcher preregisters a data analysis using linear regression but used robust regression instead without reporting the discrepancy.
(3) See also Example 1 in Selective reporting of hypotheses.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated confidence in the research</li>
<li>Reduced replicability</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Avoid vagueness in preregistration</li>
<li>Disclose and justify every divergence from the preregistration</li>
<li>Use methods that will provide robust results even when preregistration is not specific at points (e.g. blind data analysis, cross-validation)</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Link to the preregistration in the manuscript does not work or leads to a page that cannot be accessed</li>
<li>Preregistration and published study differ on important aspects</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Adam, D. (2019). A solution to psychology’s reproducibility problem just failed its first test. Science. <a href="https://doi.org/10.1126/science.aay1207">https://doi.org/10.1126/science.aay1207</a></li>
<li>Claesen, A., Gomes, S., Tuerlinckx, F., &amp; Vanpaemel, W. (2021). Comparing dream to reality: an assessment of adherence of the first generation of preregistered studies. Royal Society Open Science, 8(10), 211037. <a href="https://doi.org/10.1098/rsos.211037">https://doi.org/10.1098/rsos.211037</a></li>
<li>Nosek, B. A., Ebersole, C. R., DeHaven, A. C., &amp; Mellor, D. T. (2018). The pre-registration revolution. Proceedings of the National Academy of Sciences of the United States of America, 115(11), 2600–2606. <a href="https://doi.org/10.1073/pnas.1708274114">https://doi.org/10.1073/pnas.1708274114</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Selective citing</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">Cherry-picking citations</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Avoiding to mention studies that do not support the hypothesis of the research or even those that do support the hypotheses to make the study appear more novel.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Citation engineering
Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher overly cites empirical work that supports their hypotheses and withholds citing work that did not find the effect at all or even the opposite.
(2) Researcher omits other null findings to maximize the perceived value of a null finding.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated credibility of statements</li>
<li>Inflated confidence in the research</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Provide comprehensive coverage of related scholarly literature</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Cited studies only point into one direction</li>
<li>Important studies and experts are missing from references</li>
<li>Systematic reviews and meta-analyses are not cited</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Duyx, B., Urlings, M. J. E., Swaen, G. M. H., Bouter, L. M., &amp; Zeegers, M. P. (2017a). Scientific citations favor positive results: a systematic review and meta-analysis. Journal of Clinical Epidemiology, 88, 92–101. <a href="https://doi.org/10.1016/j.jclinepi.2017.06.002">https://doi.org/10.1016/j.jclinepi.2017.06.002</a></li>
<li>Gøtzsche, P. C. (2022). Citation bias: Questionable research practice or scientific misconduct? Journal of the Royal Society of Medicine, 115(1), 31–35. <a href="https://doi.org/10.1177/01410768221075881">https://doi.org/10.1177/01410768221075881</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Using irrelevant references</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Using citations that are not connected to the claims to increase the credibility of a statement.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Citation engineering</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Write-up</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher supports a statement with three citations and two of them are unrelated to the statement.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Inflated credibility of statements</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Cite only relevant studies</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Publications are cited without relevance to the claims</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Penders, B. (2018). Ten simple rules for responsible referencing. PLoS Computational Biology, 14(4), e1006036. <a href="https://doi.org/10.1371/journal.pcbi.1006036">https://doi.org/10.1371/journal.pcbi.1006036</a></li>
<li>Teixeira da Silva, J. A., &amp; Vuong, Q.-H. (2021). The right to refuse unwanted citations: rethinking the culture of science around the citation. Scientometrics, 126(6), 5355–5360. <a href="https://doi.org/10.1007/s11192-021-03960-9">https://doi.org/10.1007/s11192-021-03960-9</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Not linking the preregistration to the published study</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Creating a preregistration but not associating it with the published study.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">None  
</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Publication</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher preregisters a study and after conducting the research the preregistration is not mentioned in the manuscript because of too many diversions.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;">NA</td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Always link the preregistration to the manuscript and report discrepancies</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>A preregistration that fits the study is findable</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., &amp; Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in psychology, 1832. <a href="https://doi.org/10.3389/fpsyg.2016.0183">https://doi.org/10.3389/fpsyg.2016.0183</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Creating multiple publications from the same study</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">Salami slicing</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">Breaking up of research findings from the same dataset into several publications without proper justification and the disclosing of related papers.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Citation engineering</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Publication</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher conducts a study measuring several outcomes (or predictors) and publishes results in several papers with each paper focusing on just one outcome (or predictor), while not disclosing the other papers.
(2) A study on cross-cultural differences with 20 participating labs from 20 countries results in 10 publications where in each one two countries are compared.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Biased effect size estimates in meta-analyses (due to non-independence of results)</li>
<li>Inflated type I or type II error due to unknown family-wise error rate</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Preregister the publication strategy</li>
<li>Publish study results in one single publication or disclose all related papers</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Maybe</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Absence of open data</li>
<li>Description of the sample is the same over several studies by the same researcher or lab</li>
<li>Several papers exist with similar outcomes or predictors based on the same dataset by the same researcher or lab</li>
<li>The methods suggest a large study but the scope of the paper is narrow</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Broad, W. J. (1981). The publishing game: getting more for less. Science, 211(4487), 1137–1139. <a href="https://doi.org/10.1126/science.7008199">https://doi.org/10.1126/science.7008199</a></li>
<li>Kaiser, M., Drivdal, L., Hjellbrekke, J., Ingierd, H., &amp; Rekdal, O. B. (2021). Questionable Research Practices and misconduct among Norwegian researchers. Science and Engineering Ethics, 28(1), 2. <a href="https://doi.org/10.1007/s11948-021-00351-4">https://doi.org/10.1007/s11948-021-00351-4</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Declaring false authorship</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Attribution and arrangement of authorship that does not correspond to the authors’ contributions, in order to influence the publishing process, and increase the credibility of the study.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Citation engineering</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Publication</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Honorary authorship: Researcher adds a co-author who did not contribute to the manuscript.
(2) Ghost authorship: The researcher excludes a co-author who significantly contributed to the project.
(3) Controversial researcher writes a paper and publishes it under a pseudonym, so it seems that more than one person shares the same view.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Contributing authors may not get the credit they ought to get</li>
<li>Inflated confidence in the research based on the reputation of authors who were included in (or excluded from) the author list</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Explicitly declare contributions to the project (e.g., CRediT taxonomy)</li>
<li>Include everyone who made a significant contribution to the project</li>
<li>Only include authors who contributed to the project</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">No</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">None</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Fong, E. A., &amp; Wilhite, A. W. (2017). Authorship and citation manipulation in academic research. PloS One, 12(12), e0187394. <a href="https://doi.org/10.1371/journal.pone.0187394">https://doi.org/10.1371/journal.pone.0187394</a></li>
<li>Holcombe, A. O. (2019). Contributorship, not authorship: Use CRediT to indicate who did what. Publications, 7(3), 48. <a href="https://doi.org/10.3390/publications7030048">https://doi.org/10.3390/publications7030048</a></li>
<li>Wislar, J. S., Flanagin, A., Fontanarosa, P. B., &amp; Deangelis, C. D. (2011). Honorary and ghost authorship in high impact biomedical journals: a cross-sectional survey. BMJ , 343, d6128. <a href="https://doi.org/10.1136/bmj.d6128">https://doi.org/10.1136/bmj.d6128</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left" style="vertical-align: top;">Not making data accessible</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">–</span></td>
<td headers="Definition" class="gt_row gt_left" style="vertical-align: top;">The datasets and/or codebooks are not made accessible to the public and/or peer-reviewers without justifiable cause.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left" style="vertical-align: top;">Misusing open science practices</td>
<td headers="Research phase" class="gt_row gt_left" style="vertical-align: top;">Publication</td>
<td headers="Example(s)" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher doesn’t provide a publicly accessible repository link to the dataset.
(2) Data repository link is accessible, but the data is not comprehensible (e.g. lacks cleaning and organization, codebook and instructions, etc), hence it is difficult or impossible to use to reproduce findings.</span></td>
<td headers="Potential harms" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Prevents data reuse</li>
<li>Reduced reproducibility</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Data should be shared based on the FAIR (findable, accessible, interoperable, and reusable) principles and legislative context of the researcher</li>
<li>If confidential and personal information makes participants identifiable, apply masking and anonymization, and then share data</li>
<li>Use synthetic datasets when original data can’t be shared</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left" style="vertical-align: top;">Yes</td>
<td headers="Clues" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Data are not shared according to FAIR principles</li>
<li>No information in the publication on the availability of the data</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Boué, S., Byrne, M., Hayes, A. W., Hoeng, J., &amp; Peitsch, M. C. (2018). Embracing transparency through data sharing. International Journal of Toxicology, 37(6), 466–471. <a href="https://doi.org/10.1177/1091581818803880">https://doi.org/10.1177/1091581818803880</a></li>
<li>Ellis, S. E., &amp; Leek, J. T. (2018). How to share data for collaboration. The American Statistician, 72(1), 53–57. <a href="https://doi.org/10.1080/00031305.2017.1375987">https://doi.org/10.1080/00031305.2017.1375987</a></li>
<li>Quintana, D. S. (2020). A synthetic dataset primer for the biobehavioural sciences to promote reproducibility and hypothesis generation. eLife, 9. <a href="https://doi.org/10.7554/eLife.53275">https://doi.org/10.7554/eLife.53275</a></li>
<li>Wilkinson, M. D., Dumontier, M., Aalbersberg, I. J. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data, 3, 160018. <a href="https://doi.org/10.1038/sdata.2016.18">https://doi.org/10.1038/sdata.2016.18</a></li>
</ul>
</span></td></tr>
    <tr><td headers="QRP" class="gt_row gt_left gt_striped" style="vertical-align: top;">Publishing studies selectively</td>
<td headers="Alias(es) &amp; related concepts" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">File drawer problem</span></td>
<td headers="Definition" class="gt_row gt_left gt_striped" style="vertical-align: top;">Choosing which study to publish or share based on whether the findings fit expectations.</td>
<td headers="Umbrella term(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;">Cherry-picking</td>
<td headers="Research phase" class="gt_row gt_left gt_striped" style="vertical-align: top;">Publication</td>
<td headers="Example(s)" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md">(1) Researcher runs a study and finds out the results do not support their hypothesis (e.g., no significant findings). Thus the researcher does not try to publish or share the study publicly.
(2) Researcher runs several studies, and publishes only those that support the hypothesis in a multi-study paper.</span></td>
<td headers="Potential harms" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Creates inflated confidence in a multi-study paper</li>
<li>Creates publication bias</li>
</ul>
</span></td>
<td headers="Preventive measures" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Only preregister on platforms, that will eventually publish all preregistrations</li>
<li>Publish all studies, even when the findings do not support hypotheses</li>
</ul>
</span></td>
<td headers="Detectability" class="gt_row gt_left gt_striped" style="vertical-align: top;">No</td>
<td headers="Clues" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Publication bias can be estimated in meta-analysis</li>
</ul>
</span></td>
<td headers="Sources" class="gt_row gt_left gt_striped" style="vertical-align: top;"><span class="gt_from_md"><ul>
<li>Rosenthal, R. (1979). The file drawer problem and tolerance for null results. Psychological Bulletin, 86(3), 638–641. <a href="https://doi.org/10.1037/0033-2909.86.3.638">https://doi.org/10.1037/0033-2909.86.3.638</a></li>
<li>Simonsohn, U., Nelson, L. D., &amp; Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimental Psychology: General, 143(2), 534–547. <a href="https://doi.org/10.1037/a0033242">https://doi.org/10.1037/a0033242</a></li>
</ul>
</span></td></tr>
  </tbody>
  
  
</table>
</div>
</body>
</html>
